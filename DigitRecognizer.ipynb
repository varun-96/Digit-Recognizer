{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x53eaef0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('C:/Users/CanGoUser-15/Desktop/train.csv')\n",
    "y = np.array(train.pop('label'))\n",
    "x = np.array(train)/255\n",
    "len(x)\n",
    "plt.imshow(x[10].reshape(28,28), cmap = 'Greys', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = 39000\n",
    "x0 = x[:split]; x1 = x[split:]\n",
    "y0 = y[:split]; y1 = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.86860432\n",
      "Iteration 2, loss = 0.35875577\n",
      "Iteration 3, loss = 0.29123177\n",
      "Iteration 4, loss = 0.25149964\n",
      "Iteration 5, loss = 0.22368458\n",
      "Iteration 6, loss = 0.20396739\n",
      "Iteration 7, loss = 0.18618850\n",
      "Iteration 8, loss = 0.17405560\n",
      "Iteration 9, loss = 0.16180062\n",
      "Iteration 10, loss = 0.15301936\n",
      "Iteration 11, loss = 0.15248483\n",
      "Iteration 12, loss = 0.14400913\n",
      "Iteration 13, loss = 0.14014830\n",
      "Iteration 14, loss = 0.13621739\n",
      "Iteration 15, loss = 0.13473184\n",
      "Iteration 16, loss = 0.12751345\n",
      "Iteration 17, loss = 0.13126738\n",
      "Iteration 18, loss = 0.12290771\n",
      "Iteration 19, loss = 0.12680830\n",
      "Iteration 20, loss = 0.12494142\n",
      "Iteration 21, loss = 0.12506494\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.060000\n",
      "Iteration 22, loss = 0.10092988\n",
      "Iteration 23, loss = 0.08613890\n",
      "Iteration 24, loss = 0.08186245\n",
      "Iteration 25, loss = 0.07895221\n",
      "Iteration 26, loss = 0.07663372\n",
      "Iteration 27, loss = 0.07483203\n",
      "Iteration 28, loss = 0.07281115\n",
      "Iteration 29, loss = 0.07193115\n",
      "Iteration 30, loss = 0.07042574\n",
      "Iteration 31, loss = 0.06934684\n",
      "Iteration 32, loss = 0.06845636\n",
      "Iteration 33, loss = 0.06712707\n",
      "Iteration 34, loss = 0.06623387\n",
      "Iteration 35, loss = 0.06607344\n",
      "Iteration 36, loss = 0.06496781\n",
      "Iteration 37, loss = 0.06382770\n",
      "Iteration 38, loss = 0.06331696\n",
      "Iteration 39, loss = 0.06296247\n",
      "Iteration 40, loss = 0.06225617\n",
      "Iteration 41, loss = 0.06157418\n",
      "Iteration 42, loss = 0.06146598\n",
      "Iteration 43, loss = 0.06080036\n",
      "Iteration 44, loss = 0.06047924\n",
      "Iteration 45, loss = 0.06014893\n",
      "Iteration 46, loss = 0.05987412\n",
      "Iteration 47, loss = 0.05918181\n",
      "Iteration 48, loss = 0.05886141\n",
      "Iteration 49, loss = 0.05871595\n",
      "Iteration 50, loss = 0.05818968\n",
      "Iteration 51, loss = 0.05817622\n",
      "Iteration 52, loss = 0.05803080\n",
      "Iteration 53, loss = 0.05763502\n",
      "Iteration 54, loss = 0.05745910\n",
      "Iteration 55, loss = 0.05725313\n",
      "Iteration 56, loss = 0.05742372\n",
      "Iteration 57, loss = 0.05666353\n",
      "Iteration 58, loss = 0.05656108\n",
      "Iteration 59, loss = 0.05666775\n",
      "Iteration 60, loss = 0.05615619\n",
      "Iteration 61, loss = 0.05626882\n",
      "Iteration 62, loss = 0.05593799\n",
      "Iteration 63, loss = 0.05601323\n",
      "Iteration 64, loss = 0.05621361\n",
      "Iteration 65, loss = 0.05581960\n",
      "Iteration 66, loss = 0.05551070\n",
      "Iteration 67, loss = 0.05540984\n",
      "Iteration 68, loss = 0.05560759\n",
      "Iteration 69, loss = 0.05560053\n",
      "Iteration 70, loss = 0.05528759\n",
      "Iteration 71, loss = 0.05492022\n",
      "Iteration 72, loss = 0.05480008\n",
      "Iteration 73, loss = 0.05506295\n",
      "Iteration 74, loss = 0.05465311\n",
      "Iteration 75, loss = 0.05459505\n",
      "Iteration 76, loss = 0.05432149\n",
      "Iteration 77, loss = 0.05406510\n",
      "Iteration 78, loss = 0.05453534\n",
      "Iteration 79, loss = 0.05438141\n",
      "Iteration 80, loss = 0.05451570\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.012000\n",
      "Iteration 81, loss = 0.05209419\n",
      "Iteration 82, loss = 0.05120076\n",
      "Iteration 83, loss = 0.05105531\n",
      "Iteration 84, loss = 0.05095735\n",
      "Iteration 85, loss = 0.05090812\n",
      "Iteration 86, loss = 0.05082396\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.002400\n",
      "Iteration 87, loss = 0.05047561\n",
      "Iteration 88, loss = 0.05042594\n",
      "Iteration 89, loss = 0.05041046\n",
      "Iteration 90, loss = 0.05040455\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000480\n",
      "Iteration 91, loss = 0.05033418\n",
      "Iteration 92, loss = 0.05031904\n",
      "Iteration 93, loss = 0.05031361\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000096\n",
      "Iteration 94, loss = 0.05029553\n",
      "Iteration 95, loss = 0.05029495\n",
      "Iteration 96, loss = 0.05029465\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000019\n",
      "Iteration 97, loss = 0.05029107\n",
      "Iteration 98, loss = 0.05029093\n",
      "Iteration 99, loss = 0.05029086\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000004\n",
      "Iteration 100, loss = 0.05029011\n",
      "Iteration 101, loss = 0.05029008\n",
      "Iteration 102, loss = 0.05029007\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 103, loss = 0.05028992\n",
      "Iteration 104, loss = 0.05028991\n",
      "Iteration 105, loss = 0.05028991\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.1, batch_size=300, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 30), learning_rate='adaptive',\n",
       "       learning_rate_init=0.3, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.15,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver = 'sgd', activation = 'relu',\n",
    "                    hidden_layer_sizes = (100,30), \n",
    "                    learning_rate_init = 0.3, learning_rate = 'adaptive',alpha = 0.1,\n",
    "                    tol = 1e-4, max_iter = 200, shuffle = True, batch_size = 300,\n",
    "                    early_stopping = False, validation_fraction = 0.15, verbose = True)\n",
    "mlp.fit(x0,y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97033333333333338"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = mlp.predict(x1)\n",
    "accuracy = np.(y_val == y1)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Users/CanGoUser-15/Desktop/test.csv')\n",
    "test_a = np.array(test)\n",
    "pred = mlp.predict(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
